{
    "sourceFile": "bucketimages/viewsets/bucketfile_viewsets.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 35,
            "patches": [
                {
                    "date": 1746684820750,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1746684839935,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,13 @@\n from django_filters.rest_framework import DjangoFilterBackend\n from ..models import BucketFile\n from ..serializers.bucketfile_serializers import BucketFileListSerializers, BucketFileRetrieveSerializers, BucketFileWriteSerializers\n from ..utilities.importbase import *\n+from django.conf import settings\n+from django.utils import timezone\n+import boto3\n \n+\n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     # permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n@@ -19,9 +23,9 @@\n     # filterset_fields = {\n     #     'id': ['exact'],\n     # }\n \n-     def get_serializer_class(self):\n+    def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n             return BucketFileRetrieveSerializers\n"
                },
                {
                    "date": 1746684847602,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -6,10 +6,13 @@\n from ..utilities.importbase import *\n from django.conf import settings\n from django.utils import timezone\n import boto3\n+from rest_framework import viewsets, status\n+from rest_framework.filters import SearchFilter, OrderingFilter\n+from rest_framework.response import Response\n+from django_filters.rest_framework import DjangoFilterBackend\n \n-\n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     # permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n"
                },
                {
                    "date": 1746684937353,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,25 +34,25 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def perform_destroy(self, instance):\n-        \"\"\"Soft-delete and remove from R2\"\"\"\n-        try:\n-            s3_client = boto3.client(\n-                's3',\n-                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n-                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n-                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n-                region_name=settings.AWS_S3_REGION_NAME\n-            )\n-            s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n-        except Exception as e:\n-            # Optional: log this error\n-            pass\n+    \"\"\"Delete file from R2 and then delete from DB\"\"\"\n+    try:\n+        s3_client = boto3.client(\n+            's3',\n+            endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n+            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n+            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n+            region_name=settings.AWS_S3_REGION_NAME\n+        )\n+        s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n+    except Exception as e:\n+        logger.error(f\"Error deleting file from R2: {str(e)}\")\n+        # Optional: Raise exception or silently continue\n \n-        instance.is_deleted = True\n-        instance.save()\n+    instance.delete()  # Permanently remove from DB\n \n+\n     def create(self, request, *args, **kwargs):\n         \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n         file_obj = request.FILES.get('file')\n         if not file_obj:\n"
                },
                {
                    "date": 1746684943882,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -34,23 +34,22 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def perform_destroy(self, instance):\n-    \"\"\"Delete file from R2 and then delete from DB\"\"\"\n-    try:\n-        s3_client = boto3.client(\n-            's3',\n-            endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n-            aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n-            aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n-            region_name=settings.AWS_S3_REGION_NAME\n-        )\n-        s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n-    except Exception as e:\n-        logger.error(f\"Error deleting file from R2: {str(e)}\")\n-        # Optional: Raise exception or silently continue\n+        \"\"\"Delete file from R2 and then delete from DB\"\"\"\n+        try:\n+            s3_client = boto3.client(\n+                's3',\n+                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n+                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n+                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n+                region_name=settings.AWS_S3_REGION_NAME\n+            )\n+            s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n+        except Exception as e:\n+            # Optional: Raise exception or silently continue\n \n-    instance.delete()  # Permanently remove from DB\n+        instance.delete()  # Permanently remove from DB\n \n \n     def create(self, request, *args, **kwargs):\n         \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n"
                },
                {
                    "date": 1746684953890,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -15,9 +15,9 @@\n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     # permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n-    #pagination_class = MyPageNumberPagination\n+    pagination_class = MyPageNumberPagination\n     queryset = BucketFile.objects.all()\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     search_fields = ['id']\n@@ -45,8 +45,9 @@\n                 region_name=settings.AWS_S3_REGION_NAME\n             )\n             s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n         except Exception as e:\n+            pass\n             # Optional: Raise exception or silently continue\n \n         instance.delete()  # Permanently remove from DB\n \n"
                },
                {
                    "date": 1746684959098,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n     serializer_class = BucketFileListSerializers\n     # permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n     pagination_class = MyPageNumberPagination\n-    queryset = BucketFile.objects.all()\n+    queryset = BucketFile.objects.all().order_by('-id')\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     search_fields = ['id']\n     ordering_fields = ['id']\n"
                },
                {
                    "date": 1746684969246,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -16,9 +16,9 @@\n     serializer_class = BucketFileListSerializers\n     # permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n     pagination_class = MyPageNumberPagination\n-    queryset = BucketFile.objects.all().order_by('-id')\n+    queryset = BucketFile.objects.all().order_by('-last_modified')\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     search_fields = ['id']\n     ordering_fields = ['id']\n"
                },
                {
                    "date": 1746684976984,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,11 +22,11 @@\n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     search_fields = ['id']\n     ordering_fields = ['id']\n \n-    # filterset_fields = {\n-    #     'id': ['exact'],\n-    # }\n+    filterset_fields = {\n+        'id': ['exact'],\n+    }\n \n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n"
                },
                {
                    "date": 1746684982622,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,8 +24,9 @@\n     ordering_fields = ['id']\n \n     filterset_fields = {\n         'id': ['exact'],\n+        \n     }\n \n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n"
                },
                {
                    "date": 1746684993628,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,14 +19,14 @@\n     pagination_class = MyPageNumberPagination\n     queryset = BucketFile.objects.all().order_by('-last_modified')\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    search_fields = ['id']\n+    search_fields = ['id',]\n     ordering_fields = ['id']\n \n     filterset_fields = {\n         'id': ['exact'],\n-        \n+        'last_modified': ['exact', 'gte', 'lte'],\n     }\n \n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n"
                },
                {
                    "date": 1746685005614,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,10 +19,10 @@\n     pagination_class = MyPageNumberPagination\n     queryset = BucketFile.objects.all().order_by('-last_modified')\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    search_fields = ['id',]\n-    ordering_fields = ['id']\n+    search_fields = ['key', 'extension']\n+    ordering_fields = ['key', 'size', 'last_modified']\n \n     filterset_fields = {\n         'id': ['exact'],\n         'last_modified': ['exact', 'gte', 'lte'],\n"
                },
                {
                    "date": 1746685057264,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -13,9 +13,9 @@\n from django_filters.rest_framework import DjangoFilterBackend\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n-    # permission_classes = [bucketimagesPermission]\n+    permission_classes = [bucketimagesPermission]\n     # authentication_classes = [JWTAuthentication]\n     pagination_class = MyPageNumberPagination\n     queryset = BucketFile.objects.all().order_by('-last_modified')\n \n"
                },
                {
                    "date": 1746685063443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,8 +10,9 @@\n from rest_framework import viewsets, status\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n+from permissions\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [bucketimagesPermission]\n"
                },
                {
                    "date": 1746685072635,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n from rest_framework import viewsets, status\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n-from permissions\n+from permissions import \n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [bucketimagesPermission]\n"
                },
                {
                    "date": 1746685085696,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n from rest_framework import viewsets, status\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n-from permissions import \n+from permissions import ViewOnlyOrSuperuserDelete\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [bucketimagesPermission]\n"
                },
                {
                    "date": 1746685231546,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,13 +10,13 @@\n from rest_framework import viewsets, status\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n-from permissions import ViewOnlyOrSuperuserDelete\n+from .permissions import ViewOnlyOrSuperuserDelete\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n-    permission_classes = [bucketimagesPermission]\n+    permission_classes = [ViewOnlyOrSuperuserDelete]\n     # authentication_classes = [JWTAuthentication]\n     pagination_class = MyPageNumberPagination\n     queryset = BucketFile.objects.all().order_by('-last_modified')\n \n"
                },
                {
                    "date": 1746685709601,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n from rest_framework import viewsets, status\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n-from .permissions import ViewOnlyOrSuperuserDelete\n+from ..permissions import ViewOnlyOrSuperuserDelete\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n@@ -34,9 +34,17 @@\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n+    \n+       def get_queryset(self):\n+        queryset = BucketFile.objects.filter(is_deleted=False).order_by('-last_modified')\n+        for path in EXCLUDED_PATHS:\n+            cleaned_path = path.lstrip('/')\n+            queryset = queryset.exclude(key__startswith=cleaned_path)\n+        return queryset\n \n+\n     def perform_destroy(self, instance):\n         \"\"\"Delete file from R2 and then delete from DB\"\"\"\n         try:\n             s3_client = boto3.client(\n"
                },
                {
                    "date": 1746685720813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,8 +12,17 @@\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n from ..permissions import ViewOnlyOrSuperuserDelete\n \n+EXCLUDED_PATHS = [\n+    'backup/',\n+    '/backup/',\n+    'database/backup/',\n+    '/database/backup/',\n+    'backup/database/',\n+    '/backup/database/',\n+]\n+\n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n     # authentication_classes = [JWTAuthentication]\n@@ -35,9 +44,9 @@\n         elif self.action == 'retrieve':\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n     \n-       def get_queryset(self):\n+    def get_queryset(self):\n         queryset = BucketFile.objects.filter(is_deleted=False).order_by('-last_modified')\n         for path in EXCLUDED_PATHS:\n             cleaned_path = path.lstrip('/')\n             queryset = queryset.exclude(key__startswith=cleaned_path)\n"
                },
                {
                    "date": 1746686215839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,16 +24,13 @@\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n-    # authentication_classes = [JWTAuthentication]\n     pagination_class = MyPageNumberPagination\n-    queryset = BucketFile.objects.all().order_by('-last_modified')\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     search_fields = ['key', 'extension']\n     ordering_fields = ['key', 'size', 'last_modified']\n-\n     filterset_fields = {\n         'id': ['exact'],\n         'last_modified': ['exact', 'gte', 'lte'],\n     }\n@@ -43,17 +40,18 @@\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n-    \n+\n     def get_queryset(self):\n         queryset = BucketFile.objects.filter(is_deleted=False).order_by('-last_modified')\n-        for path in EXCLUDED_PATHS:\n-            cleaned_path = path.lstrip('/')\n-            queryset = queryset.exclude(key__startswith=cleaned_path)\n+        excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n+        if excluded_conditions:\n+            from functools import reduce\n+            from operator import and_\n+            queryset = queryset.filter(reduce(and_, excluded_conditions))\n         return queryset\n \n-\n     def perform_destroy(self, instance):\n         \"\"\"Delete file from R2 and then delete from DB\"\"\"\n         try:\n             s3_client = boto3.client(\n@@ -64,22 +62,23 @@\n                 region_name=settings.AWS_S3_REGION_NAME\n             )\n             s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n         except Exception as e:\n-            pass\n-            # Optional: Raise exception or silently continue\n+            pass  # Optionally log the error\n+        instance.delete()\n \n-        instance.delete()  # Permanently remove from DB\n-\n-\n     def create(self, request, *args, **kwargs):\n         \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n         file_obj = request.FILES.get('file')\n         if not file_obj:\n             return Response({'error': 'No file provided'}, status=status.HTTP_400_BAD_REQUEST)\n \n         file_name = request.data.get('name', file_obj.name)\n \n+        # 🚫 Prevent upload to excluded paths\n+        if any(file_name.startswith(p) for p in EXCLUDED_PATHS):\n+            return Response({'error': 'Uploads to this path are restricted.'}, status=status.HTTP_403_FORBIDDEN)\n+\n         try:\n             s3_client = boto3.client(\n                 's3',\n                 endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n@@ -102,25 +101,24 @@\n                 if getattr(settings, 'AWS_S3_CUSTOM_DOMAIN', None)\n                 else f\"{settings.AWS_S3_ENDPOINT_URL}/{settings.AWS_STORAGE_BUCKET_NAME}/{file_name}\"\n             )\n \n+            # Optional: if you have a `url` field in your model\n+            defaults = {\n+                'size': file_obj.size,\n+                'last_modified': timezone.now(),\n+                'content_type': file_obj.content_type,\n+                'extension': file_name.split('.')[-1].lower() if '.' in file_name else '',\n+                # 'url': file_url,  # Uncomment this line if `url` is a DB field\n+                'is_deleted': False\n+            }\n+\n             bucket_file, _ = BucketFile.objects.update_or_create(\n                 key=file_name,\n-                defaults={\n-                    'size': file_obj.size,\n-                    'last_modified': timezone.now(),\n-                    'content_type': file_obj.content_type,\n-                    'extension': file_name.split('.')[-1].lower() if '.' in file_name else '',\n-                    'url': file_url,\n-                    'is_deleted': False\n-                }\n+                defaults=defaults\n             )\n \n             serializer = self.get_serializer(bucket_file)\n             return Response(serializer.data, status=status.HTTP_201_CREATED)\n \n         except Exception as e:\n-            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n-    # @action(detail=False, methods=['get'], name=\"action_name\", url_path=\"url_path\")\n-    # def action_name(self, request, *args, **kwargs):\n-    #     return super().list(request, *args, **kwargs)\n-\n+            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746686229751,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,8 +11,9 @@\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n from ..permissions import ViewOnlyOrSuperuserDelete\n+from django\n \n EXCLUDED_PATHS = [\n     'backup/',\n     '/backup/',\n"
                },
                {
                    "date": 1746687124939,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,17 +11,18 @@\n from rest_framework.filters import SearchFilter, OrderingFilter\n from rest_framework.response import Response\n from django_filters.rest_framework import DjangoFilterBackend\n from ..permissions import ViewOnlyOrSuperuserDelete\n-from django\n+from django.db import models\n \n EXCLUDED_PATHS = [\n     'backup/',\n     '/backup/',\n     'database/backup/',\n     '/database/backup/',\n     'backup/database/',\n     '/backup/database/',\n+    \n ]\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n     serializer_class = BucketFileListSerializers\n"
                },
                {
                    "date": 1746687143944,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,8 +20,9 @@\n     'database/backup/',\n     '/database/backup/',\n     'backup/database/',\n     '/backup/database/',\n+    'static/',\n     \n ]\n \n class bucketfileViewsets(viewsets.ModelViewSet):\n"
                },
                {
                    "date": 1746694940084,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,75 +53,75 @@\n             from operator import and_\n             queryset = queryset.filter(reduce(and_, excluded_conditions))\n         return queryset\n \n-    def perform_destroy(self, instance):\n-        \"\"\"Delete file from R2 and then delete from DB\"\"\"\n-        try:\n-            s3_client = boto3.client(\n-                's3',\n-                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n-                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n-                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n-                region_name=settings.AWS_S3_REGION_NAME\n-            )\n-            s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n-        except Exception as e:\n-            pass  # Optionally log the error\n-        instance.delete()\n+    # def perform_destroy(self, instance):\n+    #     \"\"\"Delete file from R2 and then delete from DB\"\"\"\n+    #     try:\n+    #         s3_client = boto3.client(\n+    #             's3',\n+    #             endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n+    #             aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n+    #             aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n+    #             region_name=settings.AWS_S3_REGION_NAME\n+    #         )\n+    #         s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n+    #     except Exception as e:\n+    #         pass  # Optionally log the error\n+    #     instance.delete()\n \n-    def create(self, request, *args, **kwargs):\n-        \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n-        file_obj = request.FILES.get('file')\n-        if not file_obj:\n-            return Response({'error': 'No file provided'}, status=status.HTTP_400_BAD_REQUEST)\n+    # def create(self, request, *args, **kwargs):\n+    #     \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n+    #     file_obj = request.FILES.get('file')\n+    #     if not file_obj:\n+    #         return Response({'error': 'No file provided'}, status=status.HTTP_400_BAD_REQUEST)\n \n-        file_name = request.data.get('name', file_obj.name)\n+    #     file_name = request.data.get('name', file_obj.name)\n \n-        # 🚫 Prevent upload to excluded paths\n-        if any(file_name.startswith(p) for p in EXCLUDED_PATHS):\n-            return Response({'error': 'Uploads to this path are restricted.'}, status=status.HTTP_403_FORBIDDEN)\n+    #     # 🚫 Prevent upload to excluded paths\n+    #     if any(file_name.startswith(p) for p in EXCLUDED_PATHS):\n+    #         return Response({'error': 'Uploads to this path are restricted.'}, status=status.HTTP_403_FORBIDDEN)\n \n-        try:\n-            s3_client = boto3.client(\n-                's3',\n-                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n-                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n-                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n-                region_name=settings.AWS_S3_REGION_NAME\n-            )\n-            s3_client.upload_fileobj(\n-                file_obj,\n-                settings.AWS_STORAGE_BUCKET_NAME,\n-                file_name,\n-                ExtraArgs={\n-                    'ContentType': file_obj.content_type,\n-                    'CacheControl': 'max-age=86400'\n-                }\n-            )\n+    #     try:\n+    #         s3_client = boto3.client(\n+    #             's3',\n+    #             endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n\\ No newline at end of file\n+    #             aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n+    #             aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n+    #             region_name=settings.AWS_S3_REGION_NAME\n+    #         )\n+    #         s3_client.upload_fileobj(\n+    #             file_obj,\n+    #             settings.AWS_STORAGE_BUCKET_NAME,\n+    #             file_name,\n+    #             ExtraArgs={\n+    #                 'ContentType': file_obj.content_type,\n+    #                 'CacheControl': 'max-age=86400'\n+    #             }\n+    #         )\n \n-            file_url = (\n-                f\"https://{settings.AWS_S3_CUSTOM_DOMAIN}/{file_name}\"\n-                if getattr(settings, 'AWS_S3_CUSTOM_DOMAIN', None)\n-                else f\"{settings.AWS_S3_ENDPOINT_URL}/{settings.AWS_STORAGE_BUCKET_NAME}/{file_name}\"\n-            )\n+    #         file_url = (\n+    #             f\"https://{settings.AWS_S3_CUSTOM_DOMAIN}/{file_name}\"\n+    #             if getattr(settings, 'AWS_S3_CUSTOM_DOMAIN', None)\n+    #             else f\"{settings.AWS_S3_ENDPOINT_URL}/{settings.AWS_STORAGE_BUCKET_NAME}/{file_name}\"\n+    #         )\n \n-            # Optional: if you have a `url` field in your model\n-            defaults = {\n-                'size': file_obj.size,\n-                'last_modified': timezone.now(),\n-                'content_type': file_obj.content_type,\n-                'extension': file_name.split('.')[-1].lower() if '.' in file_name else '',\n-                # 'url': file_url,  # Uncomment this line if `url` is a DB field\n-                'is_deleted': False\n-            }\n+    #         # Optional: if you have a `url` field in your model\n+    #         defaults = {\n+    #             'size': file_obj.size,\n+    #             'last_modified': timezone.now(),\n+    #             'content_type': file_obj.content_type,\n+    #             'extension': file_name.split('.')[-1].lower() if '.' in file_name else '',\n+    #             # 'url': file_url,  # Uncomment this line if `url` is a DB field\n+    #             'is_deleted': False\n+    #         }\n \n-            bucket_file, _ = BucketFile.objects.update_or_create(\n-                key=file_name,\n-                defaults=defaults\n-            )\n+    #         bucket_file, _ = BucketFile.objects.update_or_create(\n+    #             key=file_name,\n+    #             defaults=defaults\n+    #         )\n \n-            serializer = self.get_serializer(bucket_file)\n-            return Response(serializer.data, status=status.HTTP_201_CREATED)\n+    #         serializer = self.get_serializer(bucket_file)\n+    #         return Response(serializer.data, status=status.HTTP_201_CREATED)\n \n-        except Exception as e:\n-            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n+    #     except Exception as e:\n+    #         return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746695004938,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,13 +46,13 @@\n         return BucketFileListSerializers\n \n     def get_queryset(self):\n         queryset = BucketFile.objects.filter(is_deleted=False).order_by('-last_modified')\n-        excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n-        if excluded_conditions:\n-            from functools import reduce\n-            from operator import and_\n-            queryset = queryset.filter(reduce(and_, excluded_conditions))\n+        # excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n+        # if excluded_conditions:\n+        #     from functools import reduce\n+        #     from operator import and_\n+        #     queryset = queryset.filter(reduce(and_, excluded_conditions))\n         return queryset\n \n     # def perform_destroy(self, instance):\n     #     \"\"\"Delete file from R2 and then delete from DB\"\"\"\n"
                },
                {
                    "date": 1746695012155,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,9 +45,9 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def get_queryset(self):\n-        queryset = BucketFile.objects.filter(is_deleted=False).order_by('-last_modified')\n+        queryset = BucketFile.objects.all.order_by('-last_modified')\n         # excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n         # if excluded_conditions:\n         #     from functools import reduce\n         #     from operator import and_\n"
                },
                {
                    "date": 1746695021425,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,9 +45,9 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def get_queryset(self):\n-        queryset = BucketFile.objects.all.order_by('-last_modified')\n+        queryset = BucketFile.objects.all().order_by('-last_modified')\n         # excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n         # if excluded_conditions:\n         #     from functools import reduce\n         #     from operator import and_\n"
                },
                {
                    "date": 1746695030848,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,9 +45,9 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def get_queryset(self):\n-        queryset = BucketFile.objects.all().order_by('-last_modified')\n+        queryset = BucketFile.objects.all().order_by('-id)\n         # excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n         # if excluded_conditions:\n         #     from functools import reduce\n         #     from operator import and_\n"
                },
                {
                    "date": 1746695049725,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,14 +30,14 @@\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n     pagination_class = MyPageNumberPagination\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    search_fields = ['key', 'extension']\n-    ordering_fields = ['key', 'size', 'last_modified']\n-    filterset_fields = {\n-        'id': ['exact'],\n-        'last_modified': ['exact', 'gte', 'lte'],\n-    }\n+    # search_fields = ['key', 'extension']\n+    # ordering_fields = ['key', 'size', 'last_modified']\n+    # filterset_fields = {\n+    #     'id': ['exact'],\n+    #     'last_modified': ['exact', 'gte', 'lte'],\n+    # }\n \n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n@@ -45,9 +45,9 @@\n             return BucketFileRetrieveSerializers\n         return BucketFileListSerializers\n \n     def get_queryset(self):\n-        queryset = BucketFile.objects.all().order_by('-id)\n+        queryset = BucketFile.objects.all().order_by('-id')\n         # excluded_conditions = [~models.Q(key__startswith=path.lstrip('/')) for path in EXCLUDED_PATHS]\n         # if excluded_conditions:\n         #     from functools import reduce\n         #     from operator import and_\n"
                },
                {
                    "date": 1746696500418,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,15 +30,19 @@\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n     pagination_class = MyPageNumberPagination\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    # search_fields = ['key', 'extension']\n-    # ordering_fields = ['key', 'size', 'last_modified']\n-    # filterset_fields = {\n-    #     'id': ['exact'],\n-    #     'last_modified': ['exact', 'gte', 'lte'],\n-    # }\n+    # ✅ Enable search, ordering, and filtering\n+    filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n \n+    search_fields = ['name', 'file', 'extension']  # 'key' replaced with 'file' or 'name'\n+    ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n+    filterset_fields = {\n+        'id': ['exact'],\n+        'created_at': ['exact', 'gte', 'lte'],\n+        'size': ['gte', 'lte'],\n+        'extension': ['exact'],\n+    }\n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n"
                },
                {
                    "date": 1746696511278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,19 +30,15 @@\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n     pagination_class = MyPageNumberPagination\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    # ✅ Enable search, ordering, and filtering\n-    filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n+    # search_fields = ['key', 'extension']\n+    # ordering_fields = ['key', 'size', 'last_modified']\n+    # filterset_fields = {\n+    #     'id': ['exact'],\n+    #     'last_modified': ['exact', 'gte', 'lte'],\n+    # }\n \n-    search_fields = ['name', 'file', 'extension']  # 'key' replaced with 'file' or 'name'\n-    ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n-    filterset_fields = {\n-        'id': ['exact'],\n-        'created_at': ['exact', 'gte', 'lte'],\n-        'size': ['gte', 'lte'],\n-        'extension': ['exact'],\n-    }\n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n"
                },
                {
                    "date": 1746696518894,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,15 +30,20 @@\n     permission_classes = [ViewOnlyOrSuperuserDelete]\n     pagination_class = MyPageNumberPagination\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n-    # search_fields = ['key', 'extension']\n-    # ordering_fields = ['key', 'size', 'last_modified']\n-    # filterset_fields = {\n-    #     'id': ['exact'],\n-    #     'last_modified': ['exact', 'gte', 'lte'],\n-    # }\n+    # ✅ Enable search, ordering, and filtering\n+    # filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n \n+    search_fields = ['name', 'file', 'extension']  # 'key' replaced with 'file' or 'name'\n+    ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n+    filterset_fields = {\n+        'id': ['exact'],\n+        'created_at': ['exact', 'gte', 'lte'],\n+        'size': ['gte', 'lte'],\n+        'extension': ['exact'],\n+    }\n+\n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n             return BucketFileWriteSerializers\n         elif self.action == 'retrieve':\n"
                },
                {
                    "date": 1746696546056,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,10 +32,9 @@\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     # ✅ Enable search, ordering, and filtering\n     # filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n-\n-    search_fields = ['name', 'file', 'extension']  # 'key' replaced with 'file' or 'name'\n+    search_fields = ['name', 'file', 'name']  # 'key' replaced with 'file' or 'name'\n     ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n     filterset_fields = {\n         'id': ['exact'],\n         'created_at': ['exact', 'gte', 'lte'],\n"
                },
                {
                    "date": 1746696551450,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,9 @@\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     # ✅ Enable search, ordering, and filtering\n     # filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n-    search_fields = ['name', 'file', 'name']  # 'key' replaced with 'file' or 'name'\n+    search_fields = ['name', 'file'']  # 'key' replaced with 'file' or 'name'\n     ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n     filterset_fields = {\n         'id': ['exact'],\n         'created_at': ['exact', 'gte', 'lte'],\n"
                },
                {
                    "date": 1746696565469,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,9 +32,9 @@\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     # ✅ Enable search, ordering, and filtering\n     # filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n-    search_fields = ['name', 'file'']  # 'key' replaced with 'file' or 'name'\n+    search_fields = ['name', 'file',]  # 'key' replaced with 'file' or 'name'\n     ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n     filterset_fields = {\n         'id': ['exact'],\n         'created_at': ['exact', 'gte', 'lte'],\n"
                },
                {
                    "date": 1746696611958,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,15 +32,15 @@\n \n     filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n     # ✅ Enable search, ordering, and filtering\n     # filter_backends = [filters.SearchFilter, filters.OrderingFilter, DjangoFilterBackend]\n-    search_fields = ['name', 'file',]  # 'key' replaced with 'file' or 'name'\n+    search_fields = ['name', 'file','content_type']  # 'key' replaced with 'file' or 'name'\n     ordering_fields = ['name', 'size', 'created_at']  # updated 'key' → 'name', 'last_modified' → 'created_at'\n     filterset_fields = {\n         'id': ['exact'],\n         'created_at': ['exact', 'gte', 'lte'],\n         'size': ['gte', 'lte'],\n-        'extension': ['exact'],\n+        'content_type': ['exact'],\n     }\n \n     def get_serializer_class(self):\n         if self.action in ['create', 'update', 'partial_update']:\n"
                }
            ],
            "date": 1746684820750,
            "name": "Commit-0",
            "content": "from rest_framework import viewsets\nfrom rest_framework.filters import SearchFilter, OrderingFilter\nfrom django_filters.rest_framework import DjangoFilterBackend\nfrom ..models import BucketFile\nfrom ..serializers.bucketfile_serializers import BucketFileListSerializers, BucketFileRetrieveSerializers, BucketFileWriteSerializers\nfrom ..utilities.importbase import *\n\nclass bucketfileViewsets(viewsets.ModelViewSet):\n    serializer_class = BucketFileListSerializers\n    # permission_classes = [bucketimagesPermission]\n    # authentication_classes = [JWTAuthentication]\n    #pagination_class = MyPageNumberPagination\n    queryset = BucketFile.objects.all()\n\n    filter_backends = [SearchFilter, DjangoFilterBackend, OrderingFilter]\n    search_fields = ['id']\n    ordering_fields = ['id']\n\n    # filterset_fields = {\n    #     'id': ['exact'],\n    # }\n\n     def get_serializer_class(self):\n        if self.action in ['create', 'update', 'partial_update']:\n            return BucketFileWriteSerializers\n        elif self.action == 'retrieve':\n            return BucketFileRetrieveSerializers\n        return BucketFileListSerializers\n\n    def perform_destroy(self, instance):\n        \"\"\"Soft-delete and remove from R2\"\"\"\n        try:\n            s3_client = boto3.client(\n                's3',\n                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n                region_name=settings.AWS_S3_REGION_NAME\n            )\n            s3_client.delete_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=instance.key)\n        except Exception as e:\n            # Optional: log this error\n            pass\n\n        instance.is_deleted = True\n        instance.save()\n\n    def create(self, request, *args, **kwargs):\n        \"\"\"Handle file upload to R2 bucket and DB entry\"\"\"\n        file_obj = request.FILES.get('file')\n        if not file_obj:\n            return Response({'error': 'No file provided'}, status=status.HTTP_400_BAD_REQUEST)\n\n        file_name = request.data.get('name', file_obj.name)\n\n        try:\n            s3_client = boto3.client(\n                's3',\n                endpoint_url=settings.AWS_S3_ENDPOINT_URL,\n                aws_access_key_id=settings.AWS_ACCESS_KEY_ID,\n                aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,\n                region_name=settings.AWS_S3_REGION_NAME\n            )\n            s3_client.upload_fileobj(\n                file_obj,\n                settings.AWS_STORAGE_BUCKET_NAME,\n                file_name,\n                ExtraArgs={\n                    'ContentType': file_obj.content_type,\n                    'CacheControl': 'max-age=86400'\n                }\n            )\n\n            file_url = (\n                f\"https://{settings.AWS_S3_CUSTOM_DOMAIN}/{file_name}\"\n                if getattr(settings, 'AWS_S3_CUSTOM_DOMAIN', None)\n                else f\"{settings.AWS_S3_ENDPOINT_URL}/{settings.AWS_STORAGE_BUCKET_NAME}/{file_name}\"\n            )\n\n            bucket_file, _ = BucketFile.objects.update_or_create(\n                key=file_name,\n                defaults={\n                    'size': file_obj.size,\n                    'last_modified': timezone.now(),\n                    'content_type': file_obj.content_type,\n                    'extension': file_name.split('.')[-1].lower() if '.' in file_name else '',\n                    'url': file_url,\n                    'is_deleted': False\n                }\n            )\n\n            serializer = self.get_serializer(bucket_file)\n            return Response(serializer.data, status=status.HTTP_201_CREATED)\n\n        except Exception as e:\n            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\n    # @action(detail=False, methods=['get'], name=\"action_name\", url_path=\"url_path\")\n    # def action_name(self, request, *args, **kwargs):\n    #     return super().list(request, *args, **kwargs)\n\n"
        }
    ]
}